None
Usage: text_learning.py [options]

Options:
  -h, --help            show this help message and exit
  --report              Print a detailed classification report.
  --chi2_select=SELECT_CHI2
                        Select some number of features using a chi-squared
                        test
  --confusion_matrix    Print the confusion matrix.
  --top10               Print ten most discriminative terms per class for
                        every classifier.
  --all_categories      Whether to use all categories or not.
  --use_hashing         Use a hashing vectorizer.
  --n_features=N_FEATURES
                        n_features when using the hashing vectorizer.
  --filtered            Remove newsgroup information that is easily overfit:
                        headers, signatures, and quoting.
  --train_filename=TRAINFILENAME
                        Input file absolute directory.
  --test_filename=TESTFILENAME

load training file
0 lines in 0.231817007065s (0.0 lines/s)
100000 lines in 8.35134196281s (11974.1190496 lines/s)
200000 lines in 16.458147049s (12152.0341651 lines/s)
300000 lines in 24.0199110508s (12489.6367698 lines/s)
400000 lines in 31.5007510185s (12698.1087986 lines/s)
500000 lines in 47.6190609932s (10499.9961573 lines/s)
load test file
0 lines in 0.157196998596s (0.0 lines/s)
100000 lines in 20.5557799339s (4864.81080279 lines/s)
500001 documents  (training set)
140272 documents  (test set)
data loaded

Extracting features from the train dataset
done in 114.862619s
training data shape: n_samples: 500001, n_features: 233981

Extracting features from the test dataset
done in 22.982494s 
testing data shape: n_samples: 140272, n_features: 233981

================================================================================
Perceptron
________________________________________________________________________________
Training: 
Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,
      n_iter=50, n_jobs=1, penalty=None, random_state=0, shuffle=False,
      verbose=0, warm_start=False)
train time: 21.715s
test time:  0.197s
f1-score:   0.411
dimensionality: 233981
density: 0.109676


================================================================================
Passive-Aggressive
________________________________________________________________________________
Training: 
PassiveAggressiveClassifier(C=1.0, fit_intercept=True, loss=hinge, n_iter=50,
              n_jobs=1, random_state=None, shuffle=False, verbose=0,
              warm_start=False)
train time: 22.581s
test time:  0.101s
f1-score:   0.411
dimensionality: 233981
density: 0.195778


================================================================================
L2 penalty
________________________________________________________________________________
Training: 
LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,
     intercept_scaling=1, loss=l2, multi_class=ovr, penalty=l2,
     random_state=None, tol=0.001, verbose=0)
train time: 35.895s
test time:  0.273s
f1-score:   0.353
dimensionality: 233981
density: 1.000000


________________________________________________________________________________
Training: 
SGDClassifier(alpha=0.0001, class_weight=None, epsilon=0.1, eta0=0.0,
       fit_intercept=True, l1_ratio=0.15, learning_rate=optimal,
       loss=hinge, n_iter=50, n_jobs=1, penalty=l2, power_t=0.5,
       random_state=None, rho=None, shuffle=False, verbose=0,
       warm_start=False)
train time: 20.260s
test time:  0.084s
f1-score:   0.333
dimensionality: 233981
density: 0.136143


================================================================================
L1 penalty
________________________________________________________________________________
Training: 
LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,
     intercept_scaling=1, loss=l2, multi_class=ovr, penalty=l1,
     random_state=None, tol=0.001, verbose=0)
train time: 119.838s
test time:  0.194s
f1-score:   0.342
dimensionality: 233981
density: 0.016225


________________________________________________________________________________
Training: 
SGDClassifier(alpha=0.0001, class_weight=None, epsilon=0.1, eta0=0.0,
       fit_intercept=True, l1_ratio=0.15, learning_rate=optimal,
       loss=hinge, n_iter=50, n_jobs=1, penalty=l1, power_t=0.5,
       random_state=None, rho=None, shuffle=False, verbose=0,
       warm_start=False)
train time: 39.643s
test time:  0.083s
f1-score:   0.333
dimensionality: 233981
density: 0.000000


================================================================================
Elastic-Net penalty
________________________________________________________________________________
Training: 
SGDClassifier(alpha=0.0001, class_weight=None, epsilon=0.1, eta0=0.0,
       fit_intercept=True, l1_ratio=0.15, learning_rate=optimal,
       loss=hinge, n_iter=50, n_jobs=1, penalty=elasticnet, power_t=0.5,
       random_state=None, rho=None, shuffle=False, verbose=0,
       warm_start=False)
train time: 42.887s
test time:  0.082s
f1-score:   0.333
dimensionality: 233981
density: 0.000000


================================================================================
NearestCentroid (aka Rocchio classifier)
________________________________________________________________________________
Training: 
NearestCentroid(metric=euclidean, shrink_threshold=None)
train time: 13.114s
test time:  0.311s
f1-score:   0.547

================================================================================
Naive Bayes
________________________________________________________________________________
Training: 
MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)
train time: 0.517s
test time:  0.076s
f1-score:   0.366
dimensionality: 233981
density: 1.000000


________________________________________________________________________________
Training: 
BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)
train time: 0.818s
test time:  0.318s
f1-score:   0.491
dimensionality: 233981
density: 1.000000


================================================================================
LinearSVC with L1-based feature selection
________________________________________________________________________________
Training: 
L1LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
      intercept_scaling=1, loss=l2, multi_class=ovr, penalty=l2,
      random_state=None, tol=0.0001, verbose=0)
train time: 140.037s
test time:  0.256s
f1-score:   0.346
dimensionality: 9639
density: 0.913145


